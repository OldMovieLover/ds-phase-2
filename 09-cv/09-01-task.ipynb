{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фаза 2 • Неделя 2 • Понедельник\n",
    "## Компьютерное зрение\n",
    "### Локализация объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchmetrics.functional.detection.iou import intersection_over_union\n",
    "import cv2\n",
    "from src.mnist_localization import get_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/mnist_detection/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:17<00:00, 560kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_detection/MNIST/raw/train-images-idx3-ubyte.gz to data/mnist_detection/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/mnist_detection/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 252kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_detection/MNIST/raw/train-labels-idx1-ubyte.gz to data/mnist_detection/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/mnist_detection/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [01:04<00:00, 25.5kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_detection/MNIST/raw/t10k-images-idx3-ubyte.gz to data/mnist_detection/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/mnist_detection/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.50MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_detection/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/mnist_detection/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# данные для этой задачи сгенерируем автоматически с помощью фунцкии\n",
    "train_loader, valid_loader = get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 100, 100]) torch.Size([32, 1]) torch.Size([32, 4])\n"
     ]
    }
   ],
   "source": [
    "# Заберем один батч и проверим размеры данных: картинки, таргета и координат боксов\n",
    "pic, label, true_box = next(iter(train_loader))\n",
    "print(pic.shape, label.shape, true_box.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 100, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# запишем в переменную размер картинки  \n",
    "IMG_SIZE = pic.shape[-1]\n",
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..255.0].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем область отрисовки картинки\n",
    "fig, ax = plt.subplots(1, 1, squeeze=True)\n",
    "# выбираем номер объекта из батча\n",
    "k = 30\n",
    "assert k < train_loader.batch_size, f\"Batch size is 32, but k={k}\"\n",
    "# выбираем картинку и преобразовываем в numpy array\n",
    "img = pic[k][0].cpu().numpy()\n",
    "# конвертируем в cv2 – она умеет рисовать поверх\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# создаем прямоугольник\n",
    "pic_label = cv2.rectangle(\n",
    "    img, \n",
    "    ((true_box[k][:2]*IMG_SIZE).numpy().astype('int')), # координаты левого верхнего угла рамки\n",
    "    ((true_box[k][2:]*IMG_SIZE).numpy().astype('int')), # координаты правого нижнего угла рамки\n",
    "    color=(0, 255, 0), thickness=2 # красный цвет, толщина 2\n",
    "    )\n",
    "ax.imshow(pic_label) # рисуем все вместе\n",
    "ax.set_xticks([]); ax.set_yticks([]) # убираем тики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalizationModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # backbone\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, stride=2),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 8, 5, stride=2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(8, 4, 5),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        # classification head: n_outputs = n_classes\n",
    "        self.clf_head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(144, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        # box regression head: n_outputs = n_coords (4)\n",
    "        self.box_head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(144, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, pic: torch.Tensor):\n",
    "        out = self.backbone(pic)\n",
    "        clf_out = self.clf_head(out)\n",
    "        box_out = self.box_head(out) \n",
    "        return clf_out, torch.sigmoid(box_out)\n",
    "\n",
    "model = LocalizationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchutils as tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "Layer                       Kernel            Output        Params        FLOPs\n",
      "===============================================================================\n",
      "0_backbone.Conv2d_0      [1, 16, 5, 5]   [32, 16, 48, 48]      416   30,670,848\n",
      "1_backbone.GELU_1                    -   [32, 16, 48, 48]        0            0\n",
      "2_backbone.MaxPool2d_2               -   [32, 16, 24, 24]        0            0\n",
      "3_backbone.Conv2d_3      [16, 8, 5, 5]    [32, 8, 10, 10]    3,208   10,265,600\n",
      "4_backbone.GELU_4                    -    [32, 8, 10, 10]        0            0\n",
      "5_backbone.Conv2d_5       [8, 4, 5, 5]      [32, 4, 6, 6]      804      926,208\n",
      "6_backbone.GELU_6                    -      [32, 4, 6, 6]        0            0\n",
      "7_clf_head.Flatten_0                 -          [32, 144]        0            0\n",
      "8_clf_head.Linear_1         [144, 128]          [32, 128]   18,560    1,175,552\n",
      "9_clf_head.GELU_2                    -          [32, 128]        0            0\n",
      "10_clf_head.Linear_3         [128, 10]           [32, 10]    1,290       81,600\n",
      "11_box_head.Flatten_0                -          [32, 144]        0            0\n",
      "12_box_head.Linear_1        [144, 128]          [32, 128]   18,560    1,175,552\n",
      "13_box_head.GELU_2                   -          [32, 128]        0            0\n",
      "14_box_head.Linear_3         [128, 64]           [32, 64]    8,256      522,240\n",
      "15_box_head.GELU_4                   -           [32, 64]        0            0\n",
      "16_box_head.Linear_5           [64, 4]            [32, 4]      260       16,256\n",
      "===============================================================================\n",
      "Total params: 51,354\n",
      "Trainable params: 51,354\n",
      "Non-trainable params: 0\n",
      "Total FLOPs: 44,833,856 / 44.83 MFLOPs\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 1.22\n",
      "Forward/backward pass size (MB): 20.94\n",
      "Params size (MB): 0.20\n",
      "Estimated Total Size (MB): 22.36\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "tu.get_model_summary(model, torch.randn(32, 1, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(images, true_boxes, pred_boxes, true_labels, pred_labels, epoch):\n",
    "    \"\"\"\n",
    "    Функция для визуализации изображений с истинными и предсказанными рамками.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "    ax.imshow(images[0].permute(1, 2, 0).cpu().numpy())  # Преобразуем изображение в формат (H, W, C)\n",
    "\n",
    "    # Рисуем истинные рамки (зеленые)\n",
    "    for box in true_boxes:\n",
    "        rect = patches.Rectangle(\n",
    "            (box[0], box[1]),  # x, y координаты верхнего левого угла\n",
    "            box[2] - box[0],    # ширина\n",
    "            box[3] - box[1],    # высота\n",
    "            linewidth=3,\n",
    "            edgecolor='green',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Рисуем предсказанные рамки (красные)\n",
    "    for box in pred_boxes:\n",
    "        rect = patches.Rectangle(\n",
    "            (box[0], box[1]),  # x, y координаты верхнего левого угла\n",
    "            box[2] - box[0],    # ширина\n",
    "            box[3] - box[1],    # высота\n",
    "            linewidth=1,\n",
    "            edgecolor='red',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Добавляем подпись\n",
    "    true_label_str = f\"True label: {true_labels[0].item()}\"\n",
    "    pred_label_str = f\"Pred label: {pred_labels[0].item()}\"\n",
    "    ax.set_title(f\"{true_label_str}, {pred_label_str}\", fontsize=14)\n",
    "\n",
    "    # Убираем оси для улучшения визуализации\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Сохраняем картинку\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=.005, nesterov=True, momentum=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage: clf_loss: 2.305 reg_loss: 6.576 total_loss: 78.320 accuracy: 0.097 iou: 0.000\n",
      "Valid stage: clf_loss: 2.305 reg_loss: 6.588 total_loss: 78.305 accuracy: 0.098 iou: 0.000\n",
      "Train stage: clf_loss: 2.305 reg_loss: 6.611 total_loss: 78.714 accuracy: 0.097 iou: 0.000\n",
      "Valid stage: clf_loss: 2.305 reg_loss: 6.563 total_loss: 78.051 accuracy: 0.098 iou: 0.000\n"
     ]
    }
   ],
   "source": [
    "log = dict()\n",
    "log['epoch_train_clf_loss'] = []\n",
    "log['epoch_valid_clf_loss'] = []\n",
    "log['epoch_train_box_loss'] = []\n",
    "log['epoch_valid_box_loss'] = []\n",
    "log['epoch_train_total_loss'] = []\n",
    "log['epoch_valid_total_loss'] = []\n",
    "log['epoch_train_accuracy'] = []\n",
    "log['epoch_valid_accuracy'] = []\n",
    "log['epoch_train_iou'] = []\n",
    "log['epoch_valid_iou'] = []\n",
    "for i in range(5):\n",
    "    batch_clf_loss = []\n",
    "    batch_reg_loss = []\n",
    "    batch_acc = []\n",
    "    batch_iou = []\n",
    "    batch_total_loss = []\n",
    "    model.train()\n",
    "    for images, labels, boxes in train_loader:\n",
    "        ############################\n",
    "        # logits: выход классификатора\n",
    "        # coords: выход регрессии на координаты\n",
    "        logits, coords = model(images)\n",
    "        ############################\n",
    "        loss_clf = F.cross_entropy(logits, labels.squeeze().long())\n",
    "        loss_box = F.smooth_l1_loss(boxes, coords, reduction='sum', beta=.6)\n",
    "        iou = intersection_over_union(coords, boxes)\n",
    "        accuracy = (logits.argmax(1) == labels.squeeze()).sum()/labels.size(0)\n",
    "        batch_acc.append(accuracy.item())\n",
    "        batch_iou.append(iou.item())\n",
    "\n",
    "        total_loss = loss_clf * (1 / (accuracy.item()+1e-1)) + loss_box * (1 / (iou.item()+1e-1))\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_reg_loss.append(loss_box.item())\n",
    "        batch_clf_loss.append(loss_clf.item())\n",
    "        batch_total_loss.append(total_loss.item())\n",
    "\n",
    "    log['epoch_train_clf_loss'].append(np.mean(batch_clf_loss))\n",
    "    log['epoch_train_box_loss'].append(np.mean(batch_reg_loss))\n",
    "    log['epoch_train_total_loss'].append(np.mean(batch_total_loss))\n",
    "    log['epoch_train_accuracy'].append(np.mean(batch_acc))\n",
    "    log['epoch_train_iou'].append(np.mean(batch_iou))\n",
    "\n",
    "\n",
    "    batch_clf_loss = []\n",
    "    batch_reg_loss = []\n",
    "    batch_acc = []\n",
    "    batch_iou = []\n",
    "    batch_total_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    for images, labels, boxes in valid_loader:\n",
    "            #########################\n",
    "        with torch.inference_mode():\n",
    "            logits, coords = model(images)\n",
    "        \n",
    "        loss_clf = F.cross_entropy(logits, labels.squeeze().long())\n",
    "        loss_box = F.smooth_l1_loss(boxes, coords, reduction='sum', beta=.6)\n",
    "        iou = intersection_over_union(coords, boxes)\n",
    "        accuracy = (logits.argmax(1) == labels.squeeze()).sum()/labels.size(0)\n",
    "        batch_acc.append(accuracy.item())\n",
    "        batch_iou.append(iou.item())\n",
    "        total_loss = loss_clf * (1 / (accuracy.item()+1e-1)) + loss_box * (1 / (iou.item()+1e-1))\n",
    "\n",
    "        batch_reg_loss.append(loss_box.item())\n",
    "        batch_clf_loss.append(loss_clf.item())\n",
    "        batch_total_loss.append(total_loss.item())\n",
    "\n",
    "        visualize_predictions(images, boxes, coords, labels, logits.argmax(1), i)\n",
    "\n",
    "    \n",
    "    log['epoch_valid_clf_loss'].append(np.mean(batch_clf_loss))\n",
    "    log['epoch_valid_box_loss'].append(np.mean(batch_reg_loss))\n",
    "    log['epoch_valid_total_loss'].append(np.mean(batch_total_loss))\n",
    "    log['epoch_valid_accuracy'].append(np.mean(batch_acc))\n",
    "    log['epoch_valid_iou'].append(np.mean(batch_iou))    \n",
    "        #########################\n",
    "\n",
    "    \n",
    "    print(f\"Train stage: clf_loss: {log['epoch_train_clf_loss'][-1]:.3f} reg_loss: {log['epoch_train_box_loss'][-1]:.3f} total_loss: {log['epoch_train_total_loss'][-1]:.3f} accuracy: {log['epoch_train_accuracy'][-1]:.3f} iou: {log['epoch_train_iou'][-1]:.3f}\")\n",
    "    print(f\"Valid stage: clf_loss: {log['epoch_valid_clf_loss'][-1]:.3f} reg_loss: {log['epoch_valid_box_loss'][-1]:.3f} total_loss: {log['epoch_valid_total_loss'][-1]:.3f} accuracy: {log['epoch_valid_accuracy'][-1]:.3f} iou: {log['epoch_valid_iou'][-1]:.3f}\")\n",
    "\n",
    "    #######################\n",
    "    # блок визуализации результатов\n",
    "    # доработай его так, чтобы после каждой эпохи распечатывалась картинка  \n",
    "    # с оригинальным боксом и предсказанным боксом (пример ниже)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, squeeze=True)\n",
    "\n",
    "        # возьмем случайную картинку из батча\n",
    "    rnd_index = np.random.randint(logits.size(0)-1)\n",
    "    img = images[rnd_index].permute(1, 2, 0).detach().cpu().numpy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    true_box = cv2.rectangle(\n",
    "            img, \n",
    "            ((boxes[rnd_index][:2].detach().cpu().numpy()*IMG_SIZE).astype('int')), # top left\n",
    "            ((boxes[rnd_index][2:].detach().cpu().numpy()*IMG_SIZE).astype('int')), # bottom right\n",
    "            color=(0, 255, 0), thickness=2\n",
    "            )\n",
    "    pred_box = cv2.rectangle(\n",
    "            img, \n",
    "            ((coords[rnd_index][:2]).detach().cpu().numpy()*IMG_SIZE).astype('int'), # top left\n",
    "            ((coords[rnd_index][2:]).detach().cpu().numpy()*IMG_SIZE).astype('int'), # bottom right\n",
    "            color=(255, 0, 0), thickness=1\n",
    "            )\n",
    "    ax.imshow(true_box)\n",
    "    ax.imshow(pred_box)\n",
    "    ax.set_axis_off()\n",
    "    plt.title(f'True label: {labels[rnd_index].item()} Pred label: {logits[rnd_index].argmax()}')\n",
    "    plt.show()\n",
    "    #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_per_epoch(log):\n",
    "    \"\"\"\n",
    "    Строит четыре строки графиков для каждой метрики по эпохам для train и valid на одном изображении.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(5, 1, figsize=(12, 16))  # Создаем сетку для 8 графиков (4 строки, 2 столбца)\n",
    "    axes = axes.flatten()  # Преобразуем двумерный массив осей в одномерный\n",
    "\n",
    "    # График 1: Accuracy\n",
    "    axes[0].plot(log['epoch_train_accuracy'], label='Train Accuracy', linestyle='--')\n",
    "    axes[0].plot(log['epoch_valid_accuracy'], label='Valid Accuracy', linestyle='-')\n",
    "    axes[0].set_title('Accuracy')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # График 2: IOU\n",
    "    axes[1].plot(log['epoch_train_iou'], label='Train IOU', linestyle='--')\n",
    "    axes[1].plot(log['epoch_valid_iou'], label='Valid IOU', linestyle='-')\n",
    "    axes[1].set_title('IOU')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('IOU')\n",
    "    axes[1].legend()\n",
    "\n",
    "    # График 3: CrossEntropy Loss (Classification Loss)\n",
    "    axes[2].plot(log['epoch_train_clf_loss'], label='Train CrossEntropy Loss', linestyle='--')\n",
    "    axes[2].plot(log['epoch_valid_clf_loss'], label='Valid CrossEntropy Loss', linestyle='-')\n",
    "    axes[2].set_title('CrossEntropy Loss')\n",
    "    axes[2].set_xlabel('Epochs')\n",
    "    axes[2].set_ylabel('Loss')\n",
    "    axes[2].legend()\n",
    "\n",
    "    # График 4: L1 Loss (Bounding Box Loss)\n",
    "    axes[3].plot(log['epoch_train_box_loss'], label='Train L1 Loss', linestyle='--')\n",
    "    axes[3].plot(log['epoch_valid_box_loss'], label='Valid L1 Loss', linestyle='-')\n",
    "    axes[3].set_title('L1 Loss')\n",
    "    axes[3].set_xlabel('Epochs')\n",
    "    axes[3].set_ylabel('Loss')\n",
    "    axes[3].legend()\n",
    "\n",
    "    # График 5: Total Loss\n",
    "    axes[4].plot(log['epoch_train_total_loss'], label='Train Total Loss', linestyle='--')\n",
    "    axes[4].plot(log['epoch_valid_total_loss'], label='Valid Total Loss', linestyle='-')\n",
    "    axes[4].set_title('Total Loss')\n",
    "    axes[4].set_xlabel('Epochs')\n",
    "    axes[4].set_ylabel('Loss')\n",
    "    axes[4].legend()\n",
    "\n",
    "    # Настройки для всего изображения\n",
    "    fig.tight_layout()  # Автоматически настроит отступы\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics_per_epoch(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой результат должен выводиться после каждой эпохи: \n",
    "\n",
    "\n",
    "<img src=\"aux/output.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируй все лоссы и метрики, которые были собраны в процессе обучения. Пример диаграммы ниже. \n",
    "\n",
    "<img src=\"aux/training_curves.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
